
# ğŸ‘ï¸ Eye-Controlled Wheelchair Using Python & Image Processing

## ğŸ” Project Overview
Imagine being able to move your wheelchair without touching a joystick or speaking a word â€” just by using your eyes. This project makes that vision a reality.

Weâ€™ve built a **smart, affordable, and fully functional eye-controlled wheelchair** using **Python, OpenCV**, and a **Raspberry Pi**, allowing users with **severe mobility limitations** to regain their independence with just a glance.

Whether you're a student, researcher, or someone passionate about assistive technology â€” this project showcases the power of **technology with purpose**.

---

## ğŸ§  Why We Built This
Every day, people with conditions like **quadriplegia, ALS, or spinal cord injuries** face physical barriers most of us can't imagine. Our goal is to use **accessible technology** to give them back what many take for granted: **mobility, independence, and dignity**.

We set out to build:
- A **touch-free wheelchair** powered by eye movements
- A **cost-effective** and **portable** system using widely available components
- An open-source foundation others can improve, adapt, and share

---

## âš™ï¸ How It Works â€” In Simple Terms
1. ğŸ‘€ A camera mounted near the userâ€™s eyes tracks eye movement.
2. ğŸ§  Python + OpenCV detects the direction theyâ€™re looking (left, right, up, down).
3. ğŸ’¡ Raspberry Pi processes this data and sends movement signals to the wheelchair.
4. ğŸ” The wheelchair moves in that direction.
5. ğŸš§ An ultrasonic sensor detects obstacles and halts movement to ensure safety.

Everything happens in **real-time**, allowing smooth and responsive control.

---

## ğŸŒŸ Key Features
- âœ… Accurate and real-time **eye movement tracking**
- âœ… Simple and intuitive **navigation interface**
- âœ… **Collision avoidance** using ultrasonic sensors
- âœ… Fully open-source and modifiable
- âœ… Lightweight and portable build

---

## ğŸ§° Tech Stack
- **Python 3** â€” Core programming language
- **OpenCV** â€” Eye tracking and image processing
- **Raspberry Pi 3B+** â€” Hardware brain of the system
- **IR Eye Camera** â€” Tracks the userâ€™s gaze
- **Ultrasonic Sensor** â€” For obstacle detection
- **L298N Motor Driver** â€” Controls the wheels

---

## ğŸ¯ Who Should Use or Explore This Project?
- Patients with **mobility impairments**
- **Hospitals** or **rehabilitation centers** looking for assistive tech
- **Students** and **researchers** working on embedded systems or AI
- **Developers and engineers** looking to contribute to inclusive tech

---

## ğŸš€ Whatâ€™s Next? (Future Scope)
Weâ€™re just getting started! Here are ideas we plan to work on:
- ğŸ‘ï¸â€ğŸ—¨ï¸ Add **blink-based commands** (like emergency stop)
- ğŸ§  Integrate **machine learning** to improve eye detection accuracy
- ğŸ“± Develop a **mobile app** for caregivers to track movement in real-time
- ğŸ“ Enable **GPS-based navigation** for outdoor movement

