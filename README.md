
# 👁️ Eye-Controlled Wheelchair Using Python & Image Processing

## 🔍 Project Overview
Imagine being able to move your wheelchair without touching a joystick or speaking a word — just by using your eyes. This project makes that vision a reality.

We’ve built a **smart, affordable, and fully functional eye-controlled wheelchair** using **Python, OpenCV**, and a **Raspberry Pi**, allowing users with **severe mobility limitations** to regain their independence with just a glance.

Whether you're a student, researcher, or someone passionate about assistive technology — this project showcases the power of **technology with purpose**.

---

## 🧠 Why We Built This
Every day, people with conditions like **quadriplegia, ALS, or spinal cord injuries** face physical barriers most of us can't imagine. Our goal is to use **accessible technology** to give them back what many take for granted: **mobility, independence, and dignity**.

We set out to build:
- A **touch-free wheelchair** powered by eye movements
- A **cost-effective** and **portable** system using widely available components
- An open-source foundation others can improve, adapt, and share

---

## ⚙️ How It Works — In Simple Terms
1. 👀 A camera mounted near the user’s eyes tracks eye movement.
2. 🧠 Python + OpenCV detects the direction they’re looking (left, right, up, down).
3. 💡 Raspberry Pi processes this data and sends movement signals to the wheelchair.
4. 🔁 The wheelchair moves in that direction.
5. 🚧 An ultrasonic sensor detects obstacles and halts movement to ensure safety.

Everything happens in **real-time**, allowing smooth and responsive control.

---

## 🌟 Key Features
- ✅ Accurate and real-time **eye movement tracking**
- ✅ Simple and intuitive **navigation interface**
- ✅ **Collision avoidance** using ultrasonic sensors
- ✅ Fully open-source and modifiable
- ✅ Lightweight and portable build

---

## 🧰 Tech Stack
- **Python 3** — Core programming language
- **OpenCV** — Eye tracking and image processing
- **Raspberry Pi 3B+** — Hardware brain of the system
- **IR Eye Camera** — Tracks the user’s gaze
- **Ultrasonic Sensor** — For obstacle detection
- **L298N Motor Driver** — Controls the wheels

---

## 🎯 Who Should Use or Explore This Project?
- Patients with **mobility impairments**
- **Hospitals** or **rehabilitation centers** looking for assistive tech
- **Students** and **researchers** working on embedded systems or AI
- **Developers and engineers** looking to contribute to inclusive tech

---

## 🚀 What’s Next? (Future Scope)
We’re just getting started! Here are ideas we plan to work on:
- 👁️‍🗨️ Add **blink-based commands** (like emergency stop)
- 🧠 Integrate **machine learning** to improve eye detection accuracy
- 📱 Develop a **mobile app** for caregivers to track movement in real-time
- 📍 Enable **GPS-based navigation** for outdoor movement

